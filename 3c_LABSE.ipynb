{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/lgaliero/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to /home/lgaliero/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Current subdirectory: Ratatouille_en-it-es-fr-de: 100%|██████████| 21/21 [00:17<00:00,  1.18it/s]    \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Download BERT LaBSE model\n",
    "tokenizer_labse = BertTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "model = BertModel.from_pretrained(\"sentence-transformers/LaBSE\", device_map='cuda')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to split text into sentences\n",
    "def split_into_sentences(text):\n",
    "    return sent_tokenize(text)\n",
    "\n",
    "# Function to get the LABSE embeddings for each sentence\n",
    "def get_labse_embedding(sentences, batch_size=8):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "        tokens = tokenizer_labse(batch, return_tensors='pt', padding=True, truncation=True)\n",
    "        tokens = {k: tokens[k].to('cuda') for k in tokens.keys()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokens)\n",
    "        batch_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return torch.cat(embeddings)\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def calculate_cosine_similarity(embeddings1, embeddings2):\n",
    "    return cosine_similarity(embeddings1.cpu(), embeddings2.cpu())\n",
    "\n",
    "# Function to process the subfolder corresponding to a single entry in multiple languages\n",
    "def process_subdirectory(directory, batch_size=8):\n",
    "    files = os.listdir(directory)\n",
    "    sentences_by_language = {}\n",
    "    max_sentences = 0\n",
    "\n",
    "    # Group texts by language and store the maximum number of sentences\n",
    "    for file in files:\n",
    "        match = re.search(r'_([a-zA-Z]{2})\\.txt$', file)\n",
    "        if match:\n",
    "            language = match.group(1)\n",
    "            if language not in sentences_by_language:\n",
    "                sentences_by_language[language] = []\n",
    "            with open(os.path.join(directory, file), 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "                sentences = split_into_sentences(text)\n",
    "                sentences_by_language[language].extend(sentences)\n",
    "                max_sentences = max(max_sentences, len(sentences))\n",
    "\n",
    "    # Calculate embeddings for each language #DIF\n",
    "    embeddings_by_language = {}\n",
    "    for language, sentences in sentences_by_language.items():\n",
    "        sentence_embeddings = get_labse_embedding(sentences, batch_size=batch_size)\n",
    "        pad_length = max_sentences - len(sentences)\n",
    "        if pad_length > 0:\n",
    "            zero_tensor = torch.zeros((pad_length, sentence_embeddings.shape[1])).to('cuda')\n",
    "            sentence_embeddings = torch.cat([sentence_embeddings, zero_tensor])\n",
    "        embeddings_by_language[language] = sentence_embeddings\n",
    "\n",
    "    # Calculate cosine similarity between all pairs of sentences #Da spiegare\n",
    "    similarities = []\n",
    "    languages = list(embeddings_by_language.keys())\n",
    "    for i in range(len(languages)):\n",
    "        lang1 = languages[i]\n",
    "        for j in range(i + 1, len(languages)):\n",
    "            lang2 = languages[j]\n",
    "            similarity = calculate_cosine_similarity(embeddings_by_language[lang1], embeddings_by_language[lang2])\n",
    "            for k in range(similarity.shape[0]):\n",
    "                for l in range(similarity.shape[1]):\n",
    "                    if k < len(sentences_by_language[lang1]) and l < len(sentences_by_language[lang2]):\n",
    "                        similarities.append({\n",
    "                            'Language 1': lang1,\n",
    "                            'Sentence 1': sentences_by_language[lang1][k],\n",
    "                            'Language 2': lang2,\n",
    "                            'Sentence 2': sentences_by_language[lang2][l],\n",
    "                            'Cosine similarity': similarity[k][l]\n",
    "                        })\n",
    "\n",
    "    return pd.DataFrame(similarities)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    main_directory = \"Gastronomia/FrenchCuisine_it-en-es-de-fr\"\n",
    "    subdirectories = os.listdir(main_directory)\n",
    "    sim_dir = \"Prova_full\"\n",
    "\n",
    "    if not os.path.exists(sim_dir):\n",
    "        os.makedirs(sim_dir)\n",
    "\n",
    "    progbar = tqdm(subdirectories, total=len(subdirectories))\n",
    "    for subdirectory in progbar:\n",
    "        progbar.set_description(desc=f'Current subdirectory: {subdirectory}')\n",
    "        subdirectory_path = os.path.join(main_directory, subdirectory)\n",
    "        if os.path.isdir(subdirectory_path):\n",
    "            df = process_subdirectory(subdirectory_path)\n",
    "            csv_filename = f\"{subdirectory}.csv\"\n",
    "            df.to_csv(os.path.join(sim_dir, csv_filename), index=False)\n",
    "            torch.cuda.empty_cache()  # Clear GPU memory\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
